import pandas as pd
import time
import os
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class KakaoMapCrawler:
    def __init__(self):
        self.driver = None
        self.wait = None

    def setup_driver(self):
        chrome_options = Options()
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)

        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=chrome_options)
        self.driver.maximize_window()
        self.wait = WebDriverWait(self.driver, 15)
        logger.info("Chrome ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ")

    def remove_dimmed_layer(self):
        try:
            self.driver.execute_script("document.getElementById('dimmedLayer')?.remove();")
            logger.info("dimmedLayer ì œê±° ì™„ë£Œ")
        except:
            pass

    def search_store(self, store_name):
        try:
            logger.info("ì¹´ì¹´ì˜¤ë§µ ì ‘ì† ì¤‘...")
            self.driver.get("https://map.kakao.com")
            time.sleep(1)

            search_input = self.wait.until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, "input#search\\.keyword\\.query"))
            )
            search_input.clear()
            search_input.send_keys(store_name)
            search_input.send_keys(Keys.ENTER)
            time.sleep(1.5)

            logger.info(f"'{store_name}' ê²€ìƒ‰ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"'{store_name}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return False

    def click_detail_view(self):
        try:
            time.sleep(1)
            self.remove_dimmed_layer()
            detail_selector = "#info\\.search\\.place\\.list > li > div.info_item > div.contact.clickArea > a.moreview"
            logger.info(f"ìƒì„¸ë³´ê¸° ë²„íŠ¼ íƒìƒ‰ ì‹œë„: {detail_selector}")

            link = WebDriverWait(self.driver, 10).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, detail_selector))
            )
            original_window = self.driver.current_window_handle
            link.click()
            logger.info("ìƒì„¸ë³´ê¸° í´ë¦­ ì™„ë£Œ, ìƒˆ íƒ­ ì—´ë¦¼ ëŒ€ê¸°")

            WebDriverWait(self.driver, 10).until(lambda d: len(d.window_handles) > 1)

            for handle in self.driver.window_handles:
                if handle != original_window:
                    self.driver.switch_to.window(handle)
                    logger.info("ìƒˆ íƒ­(ìƒì„¸ í˜ì´ì§€)ë¡œ ì „í™˜ ì™„ë£Œ")
                    break

            time.sleep(2)
            return True

        except Exception as e:
            logger.error(f"ìƒì„¸ë³´ê¸° í´ë¦­ ì‹¤íŒ¨: {e}")
            return False

    def extract_place_info(self, store_name):
        try:
            logger.info("ğŸ” ìƒì„¸ë³´ê¸° í˜ì´ì§€ ì§„ì… ì™„ë£Œ â€” ì •ë³´ ì¶”ì¶œ ì‹œì‘")

            current_url = self.driver.current_url
            logger.info(f"í˜„ì¬ URL: {current_url}")

            place_id = current_url.split("/")[-1].split("#")[0]
            logger.info(f"ì¶”ì¶œí•œ placeId: {place_id}")

            spans = self.driver.find_elements(By.CSS_SELECTOR, "span.txt_detail")
            logger.info(f"ë°œê²¬ëœ span.txt_detail ìš”ì†Œ ê°œìˆ˜: {len(spans)}")

            address = "ì£¼ì†Œ ì •ë³´ ì—†ìŒ"
            for i, span in enumerate(spans, 1):
                text = span.text.strip()
                logger.info(f"[{i}] span ë‚´ìš©: {text}")
                if "ì„œìš¸" in text:
                    address = text
                    logger.info(f"ì„ íƒëœ ì£¼ì†Œ: {address}")
                    break

            logger.info(f"âœ… ì¥ì†Œ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ â€” ì´ë¦„: {store_name}, ì£¼ì†Œ: {address}, placeId: {place_id}")

            return {
                'store_name': store_name,
                'address': address,
                'place_id': place_id
            }

        except Exception as e:
            logger.error(f"âŒ ì¥ì†Œ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None

    def click_more_button_if_exists(self, review_item):
        """
        ê°œë³„ ë¦¬ë·° ì•„ì´í…œì—ì„œ ë”ë³´ê¸° ë²„íŠ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  í´ë¦­
        """
        try:
            # ë¦¬ë·° í…ìŠ¤íŠ¸ì— '...'ì´ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸
            review_text_element = review_item.find_element(By.CSS_SELECTOR, "div.review_detail div.wrap_review a p")
            review_text = review_text_element.text.strip()
            
            if '...' not in review_text:
                logger.debug("ë”ë³´ê¸°ê°€ í•„ìš”ì—†ëŠ” ë¦¬ë·°ì…ë‹ˆë‹¤.")
                return False
            
            # ë”ë³´ê¸° ë²„íŠ¼ ì°¾ê¸° (ì—¬ëŸ¬ ê°€ëŠ¥í•œ ì…€ë ‰í„° ì‹œë„)
            more_button_selectors = [
                "span.btn_more",  # ê¸°ë³¸ ë”ë³´ê¸° ë²„íŠ¼
                "div.review_detail div.wrap_review a p span.btn_more",  # ìƒì„¸ ê²½ë¡œ
                ".btn_more"  # ê°„ë‹¨í•œ í´ë˜ìŠ¤ ì…€ë ‰í„°
            ]
            
            more_button = None
            for selector in more_button_selectors:
                try:
                    more_button = review_item.find_element(By.CSS_SELECTOR, selector)
                    if more_button and more_button.text.strip() == "ë”ë³´ê¸°":
                        logger.info(f"ë”ë³´ê¸° ë²„íŠ¼ ë°œê²¬: {selector}")
                        break
                except:
                    continue
            
            if more_button:
                # ë”ë³´ê¸° ë²„íŠ¼ì´ í´ë¦­ ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ í™•ì¸
                if more_button.is_displayed() and more_button.is_enabled():
                    # ìŠ¤í¬ë¡¤í•˜ì—¬ ë²„íŠ¼ì´ ë³´ì´ë„ë¡ ì¡°ì •
                    self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", more_button)
                    time.sleep(0.5)
                    
                    # ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­
                    more_button.click()
                    logger.info("ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì™„ë£Œ")
                    time.sleep(0.5)  # í…ìŠ¤íŠ¸ ë¡œë”© ëŒ€ê¸°
                    return True
                else:
                    logger.debug("ë”ë³´ê¸° ë²„íŠ¼ì´ í´ë¦­ ê°€ëŠ¥í•œ ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤.")
                    return False
            else:
                logger.debug("ë”ë³´ê¸° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            logger.debug(f"ë”ë³´ê¸° ë²„íŠ¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def extract_reviews(self, store_name):
        reviews = []
        try:
            logger.info("ğŸ’¬ í›„ê¸° íƒ­ í´ë¦­ ì‹œë„")
            
            # ì—¬ëŸ¬ ê°€ëŠ¥í•œ í›„ê¸° íƒ­ ì…€ë ‰í„°ë“¤ì„ ì‹œë„
            review_tab_selectors = [
                "/html/body/div[2]/main/article/div[2]/div[1]/div/ul/li[4]/a",  # li[4] ì‹œë„
                "//a[contains(text(), 'í›„ê¸°')]",  # í…ìŠ¤íŠ¸ë¡œ ì°¾ê¸°
                "//li/a[contains(text(), 'í›„ê¸°')]",  # li ì•ˆì˜ í›„ê¸° ë§í¬
                "ul.list_menu li:nth-child(4) a",  # CSS ì…€ë ‰í„°ë¡œ 4ë²ˆì§¸
                "ul.list_menu li:nth-child(5) a"   # CSS ì…€ë ‰í„°ë¡œ 5ë²ˆì§¸ (í˜¹ì‹œ ìˆœì„œê°€ ë‹¤ë¥¼ ê²½ìš°)
            ]
            
            review_tab_clicked = False
            for i, selector in enumerate(review_tab_selectors, 1):
                try:
                    logger.info(f"í›„ê¸° íƒ­ ì‹œë„ {i}: {selector}")
                    
                    if selector.startswith("//") or selector.startswith("/html"):
                        # XPath ì‚¬ìš©
                        element = WebDriverWait(self.driver, 5).until(
                            EC.element_to_be_clickable((By.XPATH, selector))
                        )
                    else:
                        # CSS ì…€ë ‰í„° ì‚¬ìš©
                        element = WebDriverWait(self.driver, 5).until(
                            EC.element_to_be_clickable((By.CSS_SELECTOR, selector))
                        )
                    
                    element.click()
                    logger.info(f"í›„ê¸° íƒ­ í´ë¦­ ì™„ë£Œ (ë°©ë²• {i})")
                    review_tab_clicked = True
                    break
                    
                except Exception as e:
                    logger.debug(f"í›„ê¸° íƒ­ ì‹œë„ {i} ì‹¤íŒ¨: {e}")
                    continue
            
            if not review_tab_clicked:
                logger.error("ëª¨ë“  í›„ê¸° íƒ­ ì…€ë ‰í„° ì‹œë„ ì‹¤íŒ¨")
                return []
                
            time.sleep(2)  # í›„ê¸° íƒ­ ë¡œë”© ëŒ€ê¸°

            # ìŠ¤í¬ë¡¤í•˜ì—¬ ë” ë§ì€ ë¦¬ë·° ë¡œë“œ
            for scroll_round in range(3):
                self.driver.execute_script("window.scrollBy(0, 1000)")
                logger.info(f"ìŠ¤í¬ë¡¤ ë‹¤ìš´ {scroll_round + 1}íšŒ ì™„ë£Œ")
                time.sleep(1)

            # ë¦¬ë·° ì»¨í…Œì´ë„ˆ ì°¾ê¸°
            review_container_xpath = "/html/body/div[2]/main/article/div[2]/div[2]/div[2]/div[3]/ul"
            try:
                review_container = self.driver.find_element(By.XPATH, review_container_xpath)
                review_items = review_container.find_elements(By.TAG_NAME, "li")
                logger.info(f"ë¦¬ë·° ì»¨í…Œì´ë„ˆì—ì„œ {len(review_items)}ê°œ ë¦¬ë·° ì•„ì´í…œ ë°œê²¬")
            except:
                logger.warning("ë¦¬ë·° ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ëŒ€ì²´ ë°©ë²• ì‚¬ìš©")
                review_items = self.driver.find_elements(By.CSS_SELECTOR, "div.group_review ul li")
                logger.info(f"ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ {len(review_items)}ê°œ ë¦¬ë·° ì•„ì´í…œ ë°œê²¬")

            processed_reviews = 0
            for i, review_item in enumerate(review_items, 1):
                try:
                    logger.info(f"ë¦¬ë·° {i} ì²˜ë¦¬ ì¤‘...")
                    
                    # ë”ë³´ê¸° ë²„íŠ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  í´ë¦­
                    more_clicked = self.click_more_button_if_exists(review_item)
                    if more_clicked:
                        logger.info(f"ë¦¬ë·° {i}: ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì™„ë£Œ")
                        time.sleep(0.5)  # í…ìŠ¤íŠ¸ í™•ì¥ ëŒ€ê¸°
                    
                    # ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì—¬ëŸ¬ ê°€ëŠ¥í•œ ì…€ë ‰í„° ì‹œë„)
                    review_text_selectors = [
                        "div.review_detail div.wrap_review a p",
                        "div.area_review div.review_detail div.wrap_review a p",
                        ".wrap_review a p"
                    ]
                    
                    review_text = None
                    for selector in review_text_selectors:
                        try:
                            review_element = review_item.find_element(By.CSS_SELECTOR, selector)
                            review_text = review_element.text.strip()
                            if review_text:
                                break
                        except:
                            continue
                    
                    if review_text and len(review_text) > 3:
                        # ë”ë³´ê¸° ë²„íŠ¼ í…ìŠ¤íŠ¸ ì œê±° (í˜¹ì‹œ í¬í•¨ë˜ì–´ ìˆì„ ê²½ìš°)
                        review_text = review_text.replace("ë”ë³´ê¸°", "").strip()
                        
                        reviews.append({
                            'store_name': store_name,
                            'review_text': review_text
                        })
                        processed_reviews += 1
                        logger.info(f"ë¦¬ë·° {i} ì¶”ì¶œ ì™„ë£Œ: {review_text[:50]}...")
                    else:
                        logger.warning(f"ë¦¬ë·° {i}: ìœ íš¨í•œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        
                except Exception as e:
                    logger.error(f"ë¦¬ë·° {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue

            logger.info(f"ì´ {processed_reviews}ê°œ ë¦¬ë·° ì¶”ì¶œ ì™„ë£Œ")
            return reviews

        except Exception as e:
            logger.error(f"âŒ ë¦¬ë·° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def crawl_from_csv(self, input_csv_path, detail_path="output/detail.csv", review_path="output/review.csv"):
        try:
            df = pd.read_csv(input_csv_path)

            if 'store_name' not in df.columns:
                logger.error("CSV íŒŒì¼ì— 'store_name' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return

            store_names = df['store_name'].tolist()
            logger.info(f"ì´ {len(store_names)}ê°œ ê°€ê²Œ í¬ë¡¤ë§ ì‹œì‘")

            os.makedirs("output", exist_ok=True)
            self.setup_driver()

            detail_list = []
            review_list = []

            for i, store_name in enumerate(store_names, 1):
                logger.info(f"[{i}/{len(store_names)}] '{store_name}' ì²˜ë¦¬ ì¤‘...")

                if not self.search_store(store_name):
                    continue

                if not self.click_detail_view():
                    continue

                place_info = self.extract_place_info(store_name)
                if place_info:
                    detail_list.append(place_info)

                    reviews = self.extract_reviews(store_name)
                    review_list.extend(reviews)

                # ìƒì„¸ í˜ì´ì§€ ë‹«ê³  ì›ë˜ ì°½ìœ¼ë¡œ ë³µê·€
                if len(self.driver.window_handles) > 1:
                    self.driver.close()
                    self.driver.switch_to.window(self.driver.window_handles[0])
                    logger.info("ìƒì„¸ í˜ì´ì§€ íƒ­ ë‹«ê³  ì›ë˜ ì°½ìœ¼ë¡œ ë³µê·€")

                time.sleep(1)

            pd.DataFrame(detail_list).to_csv(detail_path, index=False, encoding='utf-8-sig')
            pd.DataFrame(review_list).to_csv(review_path, index=False, encoding='utf-8-sig')

            logger.info(f"ê°€ê²Œ ì •ë³´ {len(detail_list)}ê°œë¥¼ '{detail_path}'ì— ì €ì¥ ì™„ë£Œ")
            logger.info(f"ë¦¬ë·° {len(review_list)}ê°œë¥¼ '{review_path}'ì— ì €ì¥ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            raise
        finally:
            if self.driver:
                self.driver.quit()

def main():
    input_file = "stores.csv"
    detail_file = "output/detail.csv"
    review_file = "output/review.csv"

    if not os.path.exists(input_file):
        logger.error(f"ì…ë ¥ íŒŒì¼ '{input_file}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        logger.info("ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœì˜ stores.csv íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”:")
        logger.info("store_name")
        logger.info("ìŠ¤íƒ€ë²…ìŠ¤ ê°•ë‚¨ì ")
        logger.info("ë§¥ë„ë‚ ë“œ í™ëŒ€ì ")
        return

    crawler = KakaoMapCrawler()

    try:
        crawler.crawl_from_csv(input_file, detail_file, review_file)
        print("\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!")
        print(f"ğŸ“ ê°€ê²Œ ì •ë³´: {detail_file}")
        print(f"ğŸ“ ë¦¬ë·°: {review_file}")

    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()